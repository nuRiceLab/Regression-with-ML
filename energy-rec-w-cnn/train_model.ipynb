{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from datagen import DataGenerator # Custom class import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global variables.\n",
    "\n",
    "Paths should be formatted _exactly_ as shown.\n",
    "\n",
    "Do not edit `TRAIN_FILES`, `VAL_FILES`, or their respective generators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"/path/to/save/\"\n",
    "\n",
    "EPOCHS = 200\n",
    "PARAMS = {\"batch_size\": 32,\n",
    "          \"views\": 3,\n",
    "          \"planes\": 500,\n",
    "          \"cells\": 500,\n",
    "          \"n_channels\": 3}\n",
    "LEARN_RATE = 0.00001\n",
    "\n",
    "EARLY_STOP = callbacks.EarlyStopping(min_delta=0.001, patience=5, monitor=\"val_loss\",\n",
    "                                     verbose=1, restore_best_weights=True)\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LEARN_RATE)\n",
    "\n",
    "VAL_SPLIT = 0.2\n",
    "FILES = [file[:-3] for file in glob(\"/path/to/batch/images.gz\")]\n",
    "np.random.shuffle(FILES)\n",
    "TRAIN_FILES = FILES[int(VAL_SPLIT*len(FILES)):]\n",
    "VAL_FILES = FILES[:int(VAL_SPLIT*len(FILES))]\n",
    "TRAIN_GENERATOR = DataGenerator(TRAIN_FILES, **PARAMS)\n",
    "VAL_GENERATOR = DataGenerator(VAL_FILES, **PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accelerate performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the model.\n",
    "\n",
    "- Input: pixel map of a neutrino collision\n",
    "  - Map the three views to the three image channels (RGB)\n",
    "- Two sequences of:\n",
    "  - 2x2, 32-filter Convolutional layer\n",
    "  - 2x2 MaxPooling layer\n",
    "- Flatten layer\n",
    "- 16-neuron Dense layer\n",
    "- Output: predicted energy in GeV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(planes, cells, channels) -> models.Sequential:\n",
    "    'Creates a model suitable for NuEnergy regression.'\n",
    "    model = models.Sequential([\n",
    "        layers.InputLayer(input_shape=(planes, cells, channels)),\n",
    "        layers.Conv2D(32, (2,2), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),   \n",
    "        layers.Conv2D(32, (2,2), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2,2)),   \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"softplus\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(PARAMS[\"planes\"], PARAMS[\"cells\"], PARAMS[\"n_channels\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model. Here, we use mean-squared error for loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=OPTIMIZER, loss=\"mean_squared_error\")\n",
    "history = model.fit(TRAIN_GENERATOR, validation_data=VAL_GENERATOR,\n",
    "                    epochs=EPOCHS, callbacks=EARLY_STOP)\n",
    "\n",
    "model.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training & validation losses over the epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Train. Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val. Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(SAVE_PATH + \"losses.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
